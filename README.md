# Deep SQL Guide ğŸš€

### ğŸ”§ Slurm Setup: Connecting to GPU Node

Before running any code, you need to connect to the GPU cluster and activate the appropriate environment.

##### 1
 Connect to the GPU Node
```bash
ssh gpu
```
#### Request a GPU with Slurm
```bash
srun -p hard --gpus-per-node=1 --constraint=A6000 --pty bash
```
ğŸ“Œ Explanation:
	â€¢	srun â†’ Launches a Slurm job interactively.
	â€¢	-p hard â†’ Specifies the partition (hard).
	â€¢	--gpus-per-node=1 â†’ Requests 1 GPU.
	â€¢	--constraint=A6000 â†’ Ensures allocation of an A6000 GPU (you can try A5000).
	â€¢	--pty bash â†’ Starts an interactive bash session.

#### Activate the Conda Environment
```bash
conda activate [env]
```
ğŸ”¹ Replace [env] with the name of your Conda environment.

â¸»

### ğŸ–¥ï¸ Starting Ollama

Ollama is required for the model. Start the Ollama server in the background:
```bash
ollama serve &
```

ğŸ”¹ The & runs the server in the background so you can continue using the terminal.

â¸»

### ğŸš€ Running the Code

Now youâ€™re ready to run Deep SQL!

ğŸ”¹ Running the Script Interactively

If you want to monitor execution in real-time, run:

```bash
cd deep_sql/scripts
bash train/run.sh
```

â¸»

â˜• Running the Script in the Background (Job Submission)

If you donâ€™t need real-time output and prefer to let it run in the background, submit it as a batch job:
```bash
cd deep_sql/scripts
sbatch train/run.sh
```
ğŸ”¹ This submits the script to Slurm and frees your terminal for other tasks.
